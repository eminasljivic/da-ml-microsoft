\subsection{Phasen}

Das Erstellen von einem \Gls{ml}-Modell wir in vier Phasen unterteilt, wo jede Phase eine bestimmte Aufgabe erfüllt.

\begin{enumerate}
    \item Vorbereitung der Daten / Preprocessing

          Jeder Anfang sollte mit einer Analyse der Daten anfangen. Dabei sollte man die Datentypen, die Anzahl der Daten oder Klassifizierungen und die Anzahl der fehlenden Werte zusammenzufassen und überblicklich darstellen (Tabellen oder Diagramme). Dies hat zwei wesentliche Gründe und einer davon ist, dass man sich mit den Daten vertraut macht und danach über ein gewisses Verstehen verfügt. Der zweite Grund ist, dass man im Verlauf der Phase die Daten so verarbeiten kann, dass man am Ende das beste Ergebnis erreicht.

          Diese Vorbereitung sollte mit stichprobenartige Daten angeführt und später durch verschiedene Strategien weitergeführt werden, die dazu dienen, entweder fehlende Daten zu bereinigen oder Ausreißer zu beseitigen.

          Wie man mit fehlenden Daten umgeht, kommt auf die Situation an.
          Hat man Zugang zu einer große Mengen an Daten könnte es sinnvoll sein, diese Daten zu löschen. Dabei bleibt die Frage offen, ob man die ganze Spalte (wenn alle fehlenden Werte in einer Spalte sind) löscht oder nur die betroffenen Zeilen. Falls die Entscheidung getroffen wird, dass die Spalte entfernt wird, muss man sich vergewissern, dass damit potenziell wichtige Daten verloren gehen. Ist die Anzahl der Datensätze jedoch klein, hat ma die Möglichkeit fehlende Werte mit dem Mittelwert oder Ähnlichem zu ersetzten, dieser kann aus allen Daten gebildet werden oder aus den Daten, die über die selbe Klassifizierung verfügen. Sind diese Mittelwerte nicht repräsentativ, kann dieser durch einen fixen Wert ersetzt werden. Ein Beispiel dafür wäre die Analyse eines Schlaganfall-Datensatzes, in Fällen eines Kindes ist zu vermuten, dass es nicht raucht und daher ist es vertretbar, dass man dafür den Wert 0/false einsetzt. Die letzte Möglichkeit ist, dass man diese Werte mithilfe eines \gls{ml}-Modells (Regression) bestimmt. \cite{MLkg}

          Das Gegenteil der fehlenden Werte sind doppelte Werte, diese können zur Überrepräsentierung von bestimmten Klassifizierung führen und sollten daher bereinigt werden. Bei ähnlichen Werte ist dies jedoch eine Interpretationssache, da es in manchen Situationen ein unbedachter Messfehler sein könnten. Ein Vorteil dieses Schrittes ist, dass man am Ende von jeder Klasse gleich viele Datensätze hat.

          Als nächstes wäre eine Analyse jeder einzelnen Spalte sinnvoll, anfangend mit dem Datentypen. Falls es sich um Enumerationswerte handelt, müssten diese in numerische Werte umgewandelt werden, außer es handelt sich um die Klassifizierungsspalte. Handelt es sich um eine Spalte, wessen Werte eine Rangfolge  (z.B.: gut, mittel, schlecht) darstellen, kann man diese mit einer Nummer zwischen 0 und 1 austauschen. Dabei ist zu beachten, dass der minimalste und maximalste Rang entweder den Wert 0 oder 1 zugeteilt bekommen und jeder Rang dazwischen einen Wert dazwischen. Sind es jedoch unabhängige Enumerationswerte könnte man mithilfe der One-Hot-Encoding Methode die Daten umwandeln, wo jeder Enumerationswerte eine extra Spalte bekommt und entweder mit 0/1 (false/true) befüllt ist. Außerdem sollten unterschiedlichen Einheiten angeglichen werden und jene textuelle Einheit aus dem Wert entfernt werden.

          Das letzte Problem sind Ausreißer, um diese zu identifizieren, müsste man die eigentlich Verteilung der Daten kennen. Danach vergleicht man verdächtigte Werte (meistens der größte oder kleinste Wert) zum Durchschnitt und entscheidet, ob es sich wirklich um unerklärliche Werte handelt. Diese können mit den gleichen Funktionen, wie bei fehlenden Werten, ersetzt werden.

    \item Visualisierung der Daten

          Die tabellarische Darstellung von Daten erschweren es dem menschlichen Auge Muster zu erkennen, um dies zu umgehen ist jede Art der Visualisierung hilfreich. Damit kann man schnell Insights und Gruppen identifizieren, außerdem kann sie auch bereits bei der Vorbereitung der Daten helfen, da man zum Beispiel mithilfe eines Boxplots Ausreißer deutlich schneller erkennen kann.

          Um dies noch leichter zu machen, ist es wichtig, dass die Farbpalette an die gegebene Situation angepasst ist, da es bei schlechter Repräsentation leicht zu Verwirrung kommen kann. Wie zum Beispiel beim Darstellen vom Wetter hier bietet sich die Farbe blau für Regen an und rot/gelb für Sonnenschein.

          Jedes Diagramm hat seine Vorteile und Nachteile, wie zum Beispiel beim Violinplot die Verteilung der Daten relativ zur Anzahl der gleichen Klassifizierung sehr gut dargestellt werden. Jedoch hat es den Nachteil, dass diese Darstellung oft irreführend sind, da sie relativ anstatt absolut ist.

          Um Zusammenhänge besser zu erkennen, kann man zwei Variablen in einem Diagramm darstellen.

    \item Training des Modells

          Der erste Schritt beim Trainieren ist die Einteilung von Trainingsdaten und Testdaten, hierzu wird eine Einteilung von 70\% zum Trainieren und 30\% zum Testen angestrebt.

          Es ist wichtig, dass die Testdaten eine ausgeglichene Anzahl von Daten pro Klassifizierung enthaltet, da es sonst zu einem unbalancierten Modell kommen könnte. Wie in \ref{overfitting} beschrieben wurde, kann sich ein Modell zu sehr an die übergeben Trainingsdaten anpassen, so, dass später die Testdaten nicht korrekt klassifiziert werden. Um dies vorzubeugen könnte man einen Teil der Testdaten als Validierungsdaten nutzen, welche die Anpassung der Hyperparameter möglich machen \cite{DatenZumTrainieren}.

          Es ist wichtig die Testdaten nur zum Testen zu benutzten, da ab dem Moment, wo das Modell diese Daten verarbeitet schon gespeichert hat und im späteren Verlauf ebenfalls zur Klassifizierung nutzt.

          Am Anfang sollte man sich für einen traditionellen Algorithmus entscheiden, damit man später jegliche Veränderungen mit einem Basiswert vergleichen kann.

    \item Evaluierung und Verbesserung

          Um herauszufinden, ob das antrainierte Modell wirklich nutzvoll und genau ist, können folgende Werte berechnet und verglichen werden: Accuracy (Genauigkeit), Precision (Präzision) oder Recall. Je nach Situation sollte man den Fokus auf einen bestimmten Werte legen. Zum Beispiel beim Testen von Wasserqualitäten würde der wichtigste Wert die Precision sein, denn man kann in Kauf nehmen, dass nicht schädliches Wasser als schädlich gekennzeichnet wird, die entgegengesetzte Situation wäre nicht akzeptabel. \cite{APR}

          \begin{figure}[H]
              \[ accuracy = \frac{correct\ predictions}{all\ predictions}  \]

              \[ precision = \frac{true\ positives}{true\ positives + false\ positives}  \]

              \[ recall = \frac{true\ positives}{true\ positives + false\ negatives}  \]

              \caption{Formeln für Accuracy, Precision und Recall}
          \end{figure}

          Nachdem das Modell mit den Testdaten überprüft wurde, kann man beurteilen, ob die Genauigkeit die Erwartungen erfüllt. Falls dies nicht der Fall ist, bestehen 3 Möglichkeiten die Genauigkeit zu verbessern.

          Als erstes kann man die ausgewählte Vorgehensweise für fehlende oder ausreißende Daten ändern oder anpassen und die zweite Möglichkeit ist es den Algorithmus des Modells zu ändern. Am Ende kann man noch selbständig die Hyperparameter anpassen, was jedoch ein mühseliger Prozess sein kann, um ihn zu verkürzen kann man einen dieser Ansätze verwenden: Gridsuche, Zufallssuche, Bayessche Optimierung, Gradientenbasierte Optimierung oder Evolutionäre Optimierung. \cite{MLkg}
\end{enumerate}