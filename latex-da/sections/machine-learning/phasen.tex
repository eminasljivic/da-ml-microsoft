\subsection{Phasen}

Das Erstellen von einem \Gls{ml}-Modell wird in vier Phasen unterteilt, wobei jede Phase eine bestimmte Aufgabe erfüllt.

\begin{enumerate}
      \item Vorbereitung der Daten / Preprocessing

            Jeder Anfang sollte mit einer Analyse der Daten anfangen. Dabei sollte man die Datentypen, die Anzahl der Daten oder Klassifizierungen und die Anzahl der fehlenden Werte zusammenzufassen und überblickbar darstellen (Tabellen oder Diagramme). Dies hat zwei wesentliche Gründe und einer davon ist, dass man sich mit den Daten vertraut macht und danach über ein gewisses Verstehen verfügt. Der zweite Grund ist, dass man im Verlauf der Phase die Daten so verarbeiten kann, dass man am Ende das beste Ergebnis erreicht.

            Diese Vorbereitung sollte mit stichprobenartigen Daten angeführt und später durch verschiedene Strategien weitergeführt werden, die dazu dienen, entweder fehlende Daten zu bereinigen oder Ausreißer zu beseitigen.

            Wie man mit fehlenden Daten umgeht, kommt auf die Situation an.
            Hat man Zugang zu einer großen Menge an Daten, könnte es sinnvoll sein, diese Daten zu löschen. Dabei bleibt die Frage offen, ob man die ganze Spalte (wenn alle fehlenden Werte in einer Spalte sind) löscht oder nur die betroffenen Zeilen. Falls die Entscheidung getroffen wird, dass die Spalte entfernt wird, muss man sich vergewissern, dass damit potenziell wichtige Daten verloren gehen. Ist die Anzahl der Datensätze jedoch klein, hat man die Möglichkeit, fehlende Werte mit dem Mittelwert oder Ähnlichem zu ersetzen, dieser kann aus allen Daten gebildet werden oder aus den Daten, die über dieselbe Klassifizierung verfügen. Sind diese Mittelwerte nicht repräsentativ, kann dieser durch einen fixen Wert ersetzt werden. Ein Beispiel dafür wäre die Analyse eines Schlaganfall-Datensatzes, in Fällen eines Kindes ist zu vermuten, dass es nicht raucht und daher ist es vertretbar, dass man dafür den Wert 0/false einsetzt. Die letzte Möglichkeit ist, dass man diese Werte mithilfe eines \gls{ml}-Modells (Regression) bestimmt. \cite{MLkg}

            Das Gegenteil der fehlenden Werte sind doppelte Werte, diese können zur Überrepräsentierung von bestimmten Klassifizierungen führen und sollten daher bereinigt werden. Bei ähnlichen Werten ist dies jedoch eine Interpretationssache, da es in manchen Situationen ein unbedachter Messfehler sein könnten. Ein Vorteil dieses Schrittes ist, dass man am Ende von jeder Klasse gleich viele Datensätze hat.

            Als Nächstes wäre eine Analyse jeder einzelnen Spalte sinnvoll, anfangend mit den Datentypen. Falls es sich um Enumerationswerte handelt, müssten diese in numerische Werte umgewandelt werden, außer es handelt sich um die Klassifizierungsspalte. Handelt es sich um eine Spalte, wessen Werte eine Rangfolge (z.B.: gut, mittel, schlecht) darstellen, kann man diese mit einer Nummer zwischen 0 und 1 austauschen. Dabei ist zu beachten, dass der minimalste und maximalste Rang entweder den Wert 0 oder 1 zugeteilt bekommen und jeder Rang dazwischen einen Wert dazwischen. Sind es jedoch unabhängige Enumerationswerte, könnte man mithilfe der One-Hot-Encoding Methode die Daten umwandeln, wo jeder Enumerationswerte eine zusätzliche Spalte bekommt und entweder mit 0/1 (false/true) befüllt ist. Außerdem sollten unterschiedliche Einheiten angeglichen werden und jene textuelle Einheit aus dem Wert entfernt werden.

            Das letzte Problem sind Ausreißer, um diese zu identifizieren, müsste man die eigentliche Verteilung der Daten kennen. Danach vergleicht man verdächtigte Werte (meistens der größte oder kleinste Wert) mit dem Durchschnitt und entscheidet, ob es sich wirklich um unerklärliche Werte handelt. Diese können mit den gleichen Funktionen wie bei fehlenden Werten ersetzt werden.

      \item Visualisierung der Daten

            Die tabellarische Darstellung von Daten erschwert dem menschlichen Auge, Muster zu erkennen, um dies zu umgehen ist jede Art der Visualisierung hilfreich. Damit kann man schnell Insights und Gruppen identifizieren, außerdem kann sie auch bereits bei der Vorbereitung der Daten helfen, da man zum Beispiel mithilfe eines Boxplots Ausreißer deutlich schneller erkennen kann.

            Um dies noch leichter zu machen, ist es wichtig, dass die Farbpalette an die gegebene Situation angepasst ist, da es bei schlechter Repräsentation leicht zu Verwirrung kommen kann. Wie zum Beispiel beim Darstellen des Wetters bietet sich die Farbe blau für Regen an und rot/gelb für Sonnenschein.

            Jedes Diagramm hat seine Vorteile und Nachteile, wie zum Beispiel beim Violinplot die Verteilung der Daten relativ zur Anzahl der gleichen Klassifizierung sehr gut dargestellt werden. Jedoch hat es den Nachteil, dass diese Darstellungen oft irreführend sind, da sie relativ anstatt absolut ist.

            Um Zusammenhänge besser zu erkennen, kann man zwei Variablen in einem Diagramm darstellen.

      \item Training des Modells

            Der erste Schritt beim Trainieren ist die Einteilung von Trainingsdaten und Testdaten, hierzu wird eine Einteilung von 70\% zum Trainieren und 30\% zum Testen angestrebt.

            Es ist wichtig, dass die Testdaten eine ausgeglichene Anzahl von Daten pro Klassifizierung enthaltet, da es sonst zu einem unausgewogenen Modell kommen könnte. Wie in \ref{overfitting} (Overfitting) beschrieben wurde, kann sich ein Modell zu sehr an die übergebenen Trainingsdaten anpassen, sodass später die Testdaten nicht korrekt klassifiziert werden. Um dies vorzubeugen, könnte man einen Teil der Testdaten als Validierungsdaten nutzen, welche die Anpassung der Hyperparameter möglich machen \cite{DatenZumTrainieren}.

            Es ist außerdem wichtig, dass die Testdaten lediglich zum Testen benutzt werden, denn sobald das Modell diese Daten verarbeitet, werden sie gespeichert und im späteren Verlauf ebenfalls zur Klassifizierung genutzt.

            Am Anfang sollte man sich für einen traditionellen Algorithmus entscheiden, damit man später jegliche Veränderungen mit einem Basiswert vergleichen kann.

      \item Evaluierung und Verbesserung

            Um herauszufinden, ob das antrainierte Modell wirklich nutzvoll und genau ist, können folgende Werte berechnet und verglichen werden: Accuracy (Genauigkeit), Precision (Präzision) oder Recall. Je nach Situation sollte man den Fokus auf einen bestimmten Wert legen. Zum Beispiel beim Testen von Wasserqualitäten würde der wichtigste Wert die Precision sein, denn man kann in Kauf nehmen, dass nicht schädliches Wasser als schädlich gekennzeichnet wird, die entgegengesetzte Situation wäre nicht akzeptabel. \cite{APR}

            \begin{figure}[H]
                  \[ accuracy = \frac{correct\ predictions}{all\ predictions}  \]

                  \[ precision = \frac{true\ positives}{true\ positives + false\ positives}  \]

                  \[ recall = \frac{true\ positives}{true\ positives + false\ negatives}  \]

                  \caption{Formeln für Accuracy, Precision und Recall}
            \end{figure}

            Nachdem das Modell mit den Testdaten überprüft wurde, kann man beurteilen, ob die Genauigkeit die Erwartungen erfüllt. Falls dies nicht der Fall ist, bestehen drei Möglichkeiten die Genauigkeit zu verbessern.

            Als Erstes kann man die ausgewählte Vorgehensweise für fehlende oder ausreißende Daten ändern oder anpassen und die zweite Möglichkeit ist es, den Algorithmus des Modells zu ändern. Am Ende kann man noch selbstständig die Hyperparameter anpassen, was jedoch ein mühseliger Prozess sein kann, um ihn zu verkürzen, kann man einen dieser Ansätze verwenden: Gridsuche, Zufallssuche, Bayessche Optimierung, Gradientenbasierte Optimierung oder Evolutionäre Optimierung. \cite{MLkg}
\end{enumerate}